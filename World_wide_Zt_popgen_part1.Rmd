---
title: "World-wide popgen Zt"
author: "Alice Feurtey"
date: "5/5/2020"
output:
  html_document:
    toc: yes
    toc_float: yes
    css: /Users/feurtey/Documents/epur_css.css
    number_sections: no
    code_folding: hide
  #html_document:
   # toc: yes
   # df_print: paged
logo: /Users/feurtey/Documents/Postdoc_Bruce/Communication/Logo_WWZt.png
---


<br><br>

> Here, I analyse and document my progress with the analysis of a world-wide whole genome sampling of *Zymoseptoria tritici*. Some of the analysis are just exploratory while some other are lined up in a clear path to answering questions related to the history of *Z.tritici* and to better understand its adaptation to various climates.

```{r setup, warning=FALSE, message = FALSE}

library(knitr)
library(reticulate)

#Spatial analyses packages
library(raster)
library(sp)
library(rgdal)
library(maps)
library(geosphere)

#Data wrangling and data viz
library(tidyverse)
library(purrr)
library(RColorBrewer)
library(plotly)
library(cowplot)
library(GGally)
library(corrplot)
library(pheatmap)
library(ggstance)
library('pophelper')
library(ggbiplot)
library(igraph)
library(ggraph)
library(ggtext)
library(scatterpie)

#Pop structure and pop genomic
library(GenomicFeatures)
library(SNPRelate) #PCA
library(LEA) #Clustering
library(pophelper)
library(PopGenome) #Summary statistics
library(gridExtra)

library(ggtree)
library(tidytree)
library(multcomp)
library(lsmeans)



#GEA
library(lfmm)

#Statistics
library(car)
library(corrr)
library(lsmeans)
library(multcomp)


#Variables
world <- map_data("world")
project_dir="/Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/"
lists_dir = "/Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/WW_PopGen/Keep_lists_samples/"

#Data directories
data_dir=paste0(project_dir, "0_Data/")
metadata_dir=paste0(project_dir, "Metadata/")
fig_dir = "/Users/feurtey/Documents/Postdoc_Bruce/Manuscripts/Feurtey_WW_Zt/Draft_figures/"

#Analysis directories
#-___________________
VAR_dir = paste0(project_dir, "1_Variant_calling/")
  depth_per_window_dir = paste0(VAR_dir, "1_Depth_per_window/")
  vcf_dir = paste0(VAR_dir, "4_Joint_calling/")
  mito_SV = paste0(VAR_dir, "6_Mito_SV/")
PopStr_dir = paste0(project_dir, "2_Population_structure/")
  nuc_PS_dir=paste0(PopStr_dir, "0_Nuclear_genome/")
  mito_PS_dir = paste0(PopStr_dir, "1_Mitochondrial_genome/")
Sumstats_dir = paste0(project_dir, "3_Sumstats_demography/")
TE_RIP_dir=paste0(project_dir, "4_TE_RIP/")
   RIP_DIR=paste0(TE_RIP_dir, "0_RIP_estimation/")
   DIM2_DIR=paste0(TE_RIP_dir, "1_Blast_from_denovo_assemblies/")
GEA_dir=paste0(project_dir, "5_GEA/")
fung_dir=paste0(project_dir, "6_Fungicide_resistance/")
virulence_dir = paste0(project_dir, "7_Virulence/")
sel_dir = paste0(project_dir, "8_Selection/")
  gene_list_dir = paste0(sel_dir, "0_Lists_unique_copy/")

#Files
vcf_name="Ztritici_global_March2021.genotyped.ALL.filtered.clean.AB_filtered.variants.good_samples.biall_SNP.max-m-1.maf-0.05.thin-1000bp"
vcf_name_nomaf="Ztritici_global_March2021.filtered-clean.AB_filtered.SNP.max-m-0.8.thin-1000bp"
vcf_name_mito = "Ztritici_global_March2021.genotyped.mt.filtered.clean.AB_filtered.variants.good_samples.max-m-80"
Zt_list = paste0(lists_dir, "Ztritici_global_March2021.genotyped.good_samples.args")
gff_file = paste0(data_dir, "Zymoseptoria_tritici.MG2.Grandaubert2015.no_CDS.gff3")
ref_fasta_file = paste0(data_dir, "Zymoseptoria_tritici.MG2.dna.toplevel.mt+.fa")
metadata_name = "Main_table_from_SQL_Feb_2020"
gene_annotation = read_tsv(paste0(data_dir, "Badet_GLOBAL_PANGENOME_TABLE.txt"))
complete_mito = read_tsv(paste0(data_dir, "Complete_mitochondria_from_blast.txt"), col_names = c("ID_file", "Contig"))

Sys.setenv(PROJECTDIR=project_dir)
Sys.setenv(VARDIR=VAR_dir)
Sys.setenv(VCFDIR=vcf_dir)
Sys.setenv(POPSTR=PopStr_dir)
Sys.setenv(MITOPOPSTR=mito_PS_dir)

Sys.setenv(SUMST=Sumstats_dir)
Sys.setenv(GEADIR=GEA_dir)

Sys.setenv(ZTLIST=Zt_list)
Sys.setenv(GFFFILE = gff_file)
Sys.setenv(REFFILE = ref_fasta_file)
Sys.setenv(VCFNAME=vcf_name)
Sys.setenv(VCFNAME_NOMAF=vcf_name_nomaf)
Sys.setenv(VCFNAME_MITO=vcf_name_mito)

#knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(results = T)


# Metadata and sample lists
##Filtered_samples
filtered_samples = bind_rows(
  read_tsv(paste0(metadata_dir, "Sample_removed_based_on_IBS.args"), col_names = "ID_file") %>%
  mutate(Filter = "IBS"),
read_tsv(paste0(metadata_dir, "Sample_with_too_much_NA.args"), col_names = "ID_file") %>%
  mutate(Filter = "High_NA"),
read_tsv(paste0(metadata_dir, "Samples_to_filter_out.args"), col_names = "ID_file") %>%
  mutate(Filter = "Mutants_etc"))

##Samples in vcf
genotyped_samples = read_tsv(Zt_list, col_names = "ID_file")

## Metadata of genotyped samples 
temp = read_tsv(paste0(metadata_dir, metadata_name, "_Description.tab"), col_names = F) %>% pull()

Zt_meta = read_tsv(paste0(metadata_dir, metadata_name, "_with_collection.tab"), 
                 col_names = temp,
                 na = "\\N", guess_max = 2000) %>%
  unite(Coordinates, Latitude, Longitude, sep = ";", remove = F) %>%
  inner_join(., genotyped_samples)  %>%
  mutate(Country = ifelse(Country == "USA", paste(Country, Region, sep = "_"), Country)) %>%
  mutate(Country = ifelse(Country == "Australia", paste(Country, Region, sep = "_"), Country)) %>%
  mutate(Country = ifelse(Country == "NZ", "New Zealand", Country)) %>%
  mutate(Country = ifelse(Country == "CH", "Switzerland", Country)) %>%
  mutate(Latitude2 = round(Latitude, 2), Longitude2 = round(Longitude, 2))

#genotyped_samples %>%
#  filter(!(ID_file %in% filtered_samples$ID_file)) %>%
#    write_tsv(Zt_list, col_names = F)



#Define colors
## For continents
#myColors <- c("#04078B", "#a10208", "#FFBA08", "#CC0044", "#5C9D06", "#129EBA","#305D1B")
myColors <- c("#DA4167", "grey", "#ffba0a", "#A20106", "#3F6E0C", "#129eba", "#8fa253" )
names(myColors) = levels(factor(Zt_meta$Continent))
Color_Continent = ggplot2::scale_colour_manual(name = "Continent", values = myColors)
Fill_Continent = ggplot2::scale_fill_manual(name = "Continent", values = myColors)

## For clustering
K_colors = c("#f9c74f", "#f9844a", "#90be6d", "#f5cac3", 
"#83c5be", "#f28482", "#577590", "#e5e5e5", "#a09abc",  "#52796f",
"#219ebc", "#003049", "#82c0cc", "#283618", "white")

## For correlations
mycolorsCorrel<- colorRampPalette(c("#0f8b8d", "white", "#a8201a"))(20)

#Random gradients
greens=c("#1B512D", "#669046", "#8CB053", "#B1CF5F", "#514F59")
blues=c("#08386E", "#1C89C9", "#28A7C0", "#B0DFE8", "grey")
```


```{bash Importation from cluster, eval = F}
# Uploading commands from the cluster to my computer.

# 1 - Variant calling - Nuclear
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/1_Variant_calling/4_Joint_calling/Ztritici_global_March2021.genotyped.ALL.filtered.clean.AB_filtered.variants.good_samples.biall* ~/Documents/Postdoc_Bruce/Projects/WW_project/1_Variant_calling/4_Joint_calling/
rsync -avP alice@130.125.25.244:/home/alice/WW_PopGen/Keep_lists_samples/Ztritici_global_March2021.genotyped.good_samples.args \
  ../WW_PopGen/Keep_lists_samples/

# 1 - Variant calling - Mito 
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/1_Variant_calling/4_Joint_calling/Ztritici_global_March2021.genotyped.mt.filtered.clean.AB_filtered.variants.good_samples.max-m-80.recode.vcf.gz  /Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/1_Variant_calling/4_Joint_calling/

rsync -avP alice@130.125.25.244:/data2/alice/WW_project/0_Data/4_Mitochondrial_genome/0_Mito_blast/Complete_mitochondria_from_blast.txt /Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/0_Data/

# 1 - Variant calling - Depth 
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/0_Data/Zymoseptoria_tritici.MG2.dna.toplevel.mt+.1kb_windows.nuc_GC.tab ../0_Data/
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/1_Variant_calling/1_Depth_per_window/Depth_per*summary.q30.txt  \
   /Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/1_Variant_calling/1_Depth_per_window/
# Depth_per_sample_core_chr_summary.q30.txt
# Depth_per_sample_summary.q30.txt
# Depth_per_chromosome_summary.q30.txt
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/1_Variant_calling/2_Depth_per_gene/Depth_per_genes_normalized.txt \
    ../1_Variant_calling/2_Depth_per_gene/
  
# 1 - Variant calling - SV
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/1_Variant_calling/6_Mito_SV/All_complete_mitochondria.* \
  /Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/1_Variant_calling/6_Mito_SV/
#All_complete_mitochondria.mcoords
#All_complete_mitochondria.snps

# 2 -Population structure
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/2_Population_structure/1_Mitochondrial_genome/Mitochondria.blast_results.tsv\
    ../2_Population_structure/1_Mitochondrial_genome/


# 4 - TE and RIP
rsync -avP \
  alice@130.125.25.244:/data2/alice/WW_project/4_TE_RIP/0_RIP_estimation/Nb_reads* \
  /Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/4_TE_RIP/0_RIP_estimation/
# Nb_reads_per_TE.txt
# Nb_reads.txt
rsync -avP \
  alice@130.125.25.244:/data2/alice/WW_project/4_TE_RIP/0_RIP_estimation/Composite_index.txt \
  /Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/4_TE_RIP/0_RIP_estimation/
rsync -avP   alice@130.125.25.244:/data2/alice/WW_project/4_TE_RIP/1_Blast_from_denovo_assemblies/1_Blast_dim2_deRIPped/ \
 /Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/4_TE_RIP/1_Blast_from_denovo_assemblies/
  
  
# 5 - GEA
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/5_GEA/output/* ~/Documents/Postdoc_Bruce/Projects/WW_project/5_GEA/


# 6 - Fungicides
rsync -avP alice@130.125.25.244:/data2/alice/WW_project/6_Fungicide_resistance/genotypes_tidy_format.tab ~/Documents/Postdoc_Bruce/Projects/WW_project/6_Fungicide_resistance/
```


# Sampling
***


The sampling of _Z.tritici_ isolated from the natural environment covers almost the entirety of the wheat-grown continents. It is, however, highly heterogeous. Europe has the highest sampling density. Several locations are heavily sampled, such a fields in Switzerland or the US.
Some of the available genomes are still under embargo (waiting for the publication of their creator). We are also thinking about sequencing more genomes. Here you can view these different datasets on a map. Please select and unselect the different values to have a view of the changes with added datasets.

* "Usable genomes" are the genomes we have already and which have no embargo on publication.
* "Present and future" are the isolates sequenced already and without embargo plus the planned sequencing
* "Present, future and JGI" are the isolates described above plus the JGI genomes

```{r Sampling map , message = F, warning=F, eval= T}

#kable(Zt_meta %>% dplyr::count(Collection, name = "Number of genomes"))
Zt_meta %>% dplyr::count(Collection, name = "Number of genomes")
max_circle = max(Zt_meta %>%
  dplyr::count(Latitude, Longitude, name = "Number_genomes") %>%
  dplyr::select(Number_genomes))

temp = Zt_meta %>%
   dplyr::count(Country, Latitude, Longitude, name = "Number_genomes") %>%
   filter(Number_genomes > 0)

empty_map = ggplot() + theme_void() +
  geom_polygon(data = world, aes(x=long, y = lat, group = group), fill="#ede7e3", alpha=0.7)
empty_map

empty_map +
  geom_point (data = temp, aes(x=as.numeric(Longitude), y=as.numeric(Latitude),
                                    size=Number_genomes,
                                    text = Country),
                                  alpha = 0.6, color = "#16697a") +
  scale_size("Number of genomes", limits = c(1, max_circle))



```




The sampling also covers a wide range of years: starting from 1990 to 2017. Just as with the geographical repartition, some years are heavily sampled, reflecting sampling in specific fields done for previous experiments.
```{r plot sampling time, message = F, warning=F}
temp = as_tibble(c(min(Zt_meta$Sampling_Date, na.rm = T) : max(Zt_meta$Sampling_Date, na.rm = T))) %>%
  mutate(`Sampling year` = as.character(value))

sum_temp = Zt_meta %>%
    mutate(`Sampling year` = as.character(Sampling_Date)) %>%
    dplyr::count(`Sampling year`, Continent) %>%
    full_join(., temp) %>%
    mutate(`Genome number` = replace_na(n, 0))

sum_temp %>%
ggplot(aes(x=`Sampling year`, y =`Genome number`, fill = Continent)) +
  geom_bar(stat = "identity") +
  theme_bw() + theme(axis.title = element_blank(),
                     axis.text.x = element_text(angle = 60, hjust = 1)) +
  Fill_Continent
```

```{r list samples per country}
countries = dplyr::count(Zt_meta, Country, Continent)

countries %>% filter(n >= 8) %>%
  ggplot(aes(x = Country, y =n, fill = Continent)) +
    geom_bar(stat = "identity") +
    Fill_Continent +
    theme_cowplot() +
    labs(x = element_blank(), y = "Number of samples") +
    theme(axis.text.x = element_text(angle = 40, hjust = 1, vjust = 1))

for (country in filter(countries, n >= 8) %>% pull(Country)) {
  country_name = str_replace(country, pattern = " ", replacement = "_")
  file_name = paste0(PopStr_dir, "Sample_list_", country_name, ".args")
  
  Zt_meta %>% filter(Country == country) %>%
    dplyr::select(ID_file) %>%
    write_tsv(file = file_name, col_names = F)
}
```


```{r subset country sampling}

for ( min_number in c(6, 10) ) {
  
  small_pops = Zt_meta %>%
    filter(!is.na(Country) & !is.na(Sampling_Date)) %>%
    dplyr::count(Country, Latitude2, Longitude2, Sampling_Date, name = "Number_genomes") %>%
    filter( Number_genomes >= min_number ) 
  
  map1 = ggplot() + 
    theme_void() +
    geom_polygon(data = map_data("world"), aes(x=long, y = lat, group = group), fill="#ede7e3")  +
    scale_size("Number of genomes", limits = c(1, max_circle))  +
    theme(legend.position = "None", 
          panel.border  = element_rect(fill=NA, colour = "grey",size = 0.5, linetype = 1))+
      scale_fill_manual(values = c("grey", K_colors) )
  
  p1 = map1 + coord_cartesian(xlim=c(-20, 60), ylim=c(20, 70)) + 
    geom_point(data = small_pops, 
               mapping = aes(x=Longitude2, y=Latitude2, size=Number_genomes),
               alpha = 0.6, color = "#16697a")
  
  p2 = map1 + coord_cartesian(xlim=c(-160, -40), ylim=c(-80, 80)) + 
    geom_point(data = small_pops, 
               mapping = aes(x=Longitude2, y=Latitude2, size=Number_genomes),
               alpha = 0.6, color = "#16697a")
  
  p3 = map1 + coord_cartesian(xlim=c(115, 175), ylim=c(-65, 10)) + 
    geom_point(data = small_pops, 
               mapping = aes(x=Longitude2, y=Latitude2, size=Number_genomes),
               alpha = 0.6, color = "#16697a")
  
  aus_map = cowplot::plot_grid(p3, get_legend(isolate_map), ncol = 2, rel_widths = c(1, 0.9))
  ligne = cowplot::plot_grid(p1, aus_map, ncol = 1,  rel_heights = c(1, 0.7))
  cowplot::plot_grid(p2, ligne, ncol = 2, rel_widths = c(0.7, 1)) 
  
  
  
  for (t in 1:nrow(small_pops)) {
    country = pull(small_pops[t, "Country"])
    year = pull(small_pops[t, "Sampling_Date"])
    lat = pull(small_pops[t, "Latitude2"])
    long = pull(small_pops[t, "Longitude2"])
    country_name = str_replace(country, pattern = " ", replacement = "_")
    
    for (i in 1:10 ){
      
      file_name = paste0(PopStr_dir, "Sample_list_subset_", 
                         paste(min_number, country_name, year, lat, long, i, sep = "_"), 
                         ".args")
      
      temp = Zt_meta %>% 
        filter(Country == country) %>%
        filter(Sampling_Date == year)  %>% 
        filter(Latitude2 == lat) %>%
        filter(Longitude2 == long) %>%
        dplyr::select(ID_file) %>%
        pull()
      
      write_tsv(as.tibble(sample(temp, size = min_number)), file = file_name, col_names = F) 
    }
  }
}

```


<br><br>


# Variant calling
***
## Whole chromosomes SNV
__Question__: How prelavent is aneuploidy in natural populations of _Z.tritici_? In the case of accessory chromosomes, is there a correlation between phylogeny, environment, host or time and the presence/absence of some chromosomes?

__Methods__: Based on the depth of coverage for all samples, we can identify for both core and accessory chromosomes whether each isolates includes 1, 0 or several copies. 

```{r chr depth}
core_depth = read_tsv(paste0(depth_per_window_dir, "Depth_per_sample_core_chr_summary.q30.txt")) %>%
  mutate(Median_core = Median)

chrom_depth = read_tsv(paste0(depth_per_window_dir, "Depth_per_chromosome_summary.q30.txt")) %>%
  left_join(., core_depth %>% 
  dplyr::select(Sample, Median_core)) %>%
  mutate(Relative_depth = Median/Median_core) %>%
  left_join(.,Zt_meta, by = c("Sample" = "ID_file")) %>%
  filter(CHROM != "mt") %>%
  mutate(Sample = fct_reorder(Sample, Sampling_Date)) %>%
  mutate(Sample = fct_reorder(Sample, Country)) %>%
  mutate(Sample = fct_reorder(Sample, Continent)) 

heatmap_depth = chrom_depth %>%
  filter(CHROM != "mt") %>%
  ggplot(aes(x = as.numeric(CHROM), y=Sample, fill=Relative_depth)) +
  geom_tile() + scale_fill_gradient2(low="white", high = "#479DAE") +
  geom_vline(xintercept = 13.5, linetype = "longdash", colour = "gray20") +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(), axis.ticks.y=element_blank()) +
  labs(fill = "Depth", x= "Chromosome") + xlim(c(0.5, 21.5))


plot_continent = chrom_depth %>%
  ggplot(aes(x = 1, y=Sample, fill=Continent)) +
  geom_tile(aes(width = 2))  +
  theme_classic() +
  theme(axis.text.y = element_blank(), axis.ticks.y=element_blank(),
        legend.position="left",
        axis.text.x=element_text(colour="white")) +
  labs(y= "Isolate") + Fill_Continent

plot_grid(plot_continent, heatmap_depth, rel_widths = c(2, 5))

```
In the heatmap, I represent the depth normalized by the median depth over all core chromosomes. As expected, the copy-number variation at the chromosome scale affects mostly the accessory chromosomes (AC). There is some presence of supernumerary AC and a lot of presence-absence variation. Supernumerary chromosomes can also be found in the core chromosomes but this is almost anecdotal as over the whole sampling this was found only in 9 cases.

```{r low/high CHR}
Lthres = 0.50
Hthres = 1.50
depth = chrom_depth %>%
  dplyr::mutate(Depth_is = ifelse(Relative_depth > Hthres, "High",ifelse(Relative_depth < Lthres, "Low", "Normal"))) %>%
  mutate(CHROM = fct_reorder(CHROM, as.numeric(CHROM)))  

bar_Ndepth_per_CHR =ggplot(depth, aes(x = CHROM, fill = Depth_is)) +
  geom_bar(stat = "count") +
  scale_fill_manual(values =c("#16697a", "#82c0cc", "#EDE7E3")) +
    theme_light()+
    labs(x= "Chromosome", y = "Number of isolates")

#lollipop plots
##For high normalized depth values
temp = depth %>%
  filter(Depth_is == "High") %>%
  dplyr::group_by(CHROM) %>%
  dplyr::count() %>%
  mutate(CHROM = fct_reorder(CHROM, as.numeric(CHROM))) 
lolhigh =  ggplot(temp, aes(x = as.character(CHROM), y = n)) +
    geom_segment( aes(x=as.character(CHROM), xend=as.character(CHROM), y=0, yend=max(temp$n)),
                  color="grey80", size = 1) +
    geom_segment( aes(x=as.character(CHROM), xend=as.character(CHROM), y=0, yend=n),
                  color="grey20", size = 1) +
    geom_point( color="#16697a", size=4)  +
    geom_text(aes( label = n,
                     y= n), stat= "identity",
              hjust = -0.5, vjust = -0.2) +
    theme_light() +
    theme(
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10)
    ) +
    ylim(c(0,max(temp$n)+2+ max(temp$n)*0.1)) +
    labs(x= "Chromosome", y = "Number of isolates with supernumerary chromosome") +
    coord_flip()

##For low normalized depth values
temp = depth %>%
  filter(Depth_is == "Low") %>%
  dplyr::group_by(CHROM) %>%
  dplyr::count()%>%
  mutate(CHROM = fct_reorder(CHROM, as.numeric(CHROM)))

lollow = ggplot(temp, aes(x = CHROM, y = n)) +
    geom_segment( aes(x=CHROM, xend=CHROM, y=0, yend=max(temp$n)),
                  color="grey80", size = 1) +
    geom_segment( aes(x=CHROM, xend=CHROM, y=0, yend=n),
                  color="grey20", size = 1) +
    geom_point( color="#82c0cc", size=4)  +
    geom_text(aes( label = n,
                     y= n), stat= "identity",
              hjust = -0.5, vjust = -0.2) +
    theme_light() +
    theme(
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(size = 10),
    axis.text.y = element_text(size = 10)
    ) +
    ylim(c(0,max(temp$n)+ max(temp$n)*0.1)) +
    labs( x= "Chromosome", y = "Number of isolates without chromosome") +
    coord_flip()

bottom_row <- cowplot::plot_grid(lolhigh, lollow, labels = c('B', 'C'), label_size = 12)

plot_grid(bar_Ndepth_per_CHR, bottom_row, labels = c('A', ''), label_size = 12, ncol = 1)
```

Here is a table including the isolates with supernumerary _core_ chromosomes.
```{r Supernumerary chromosomes table}
depth  %>%
  dplyr::filter(Depth_is == "High") %>%
  dplyr::filter(as.numeric(CHROM) < 13) %>%
  dplyr::select(Sample, CHROM, Median, Median_core, Collection, Country)
```

And an overlook of the accessory chromosomes PAV per continent (only considering continents with more than 10 isolates).
```{r AC chr PAV per continent}
depth %>%
  dplyr::filter(as.numeric(CHROM) > 13) %>%
  dplyr::group_by(Continent, CHROM) %>%
  dplyr::mutate(Count_sample_per_continent = n()) %>%
  dplyr::filter(Count_sample_per_continent >= 10) %>%
  ggplot(aes(x = Continent, fill = Depth_is)) +
  geom_bar(position = "fill" ) + facet_wrap(CHROM~.) +
  theme_light() +
  scale_fill_manual(values = c("#16697a", "#82c0cc", "#EDE7E3")) +
    theme(axis.text.x = element_text(angle = 40, hjust = 1)) +
  ylab("Proportion of chromosomes") + xlab("")
```


## GC bias
Estimates for the GC bias were done per isolate in the Depth.Rmd script. Here, I simply load this data and represent it graphically.
```{r GC per win}

# 

GC_per_window = read_tsv(paste0(data_dir, "Zymoseptoria_tritici.MG2.dna.toplevel.mt+.1kb_windows.nuc_GC.tab")) %>%
  mutate(GC = round(`5_pct_gc`, 2)) %>%
  filter( !is.na(`#1_usercol`))

temp = GC_per_window %>%
  filter(`#1_usercol` < 14)  %>%
  dplyr::select(CHROM = `#1_usercol`, Win_start = `2_usercol`, Win_stop = `3_usercol`, GC) %>%
  group_by(GC) %>%
  dplyr::count() 

# Histogram of GC values
xint = median(GC_per_window$GC)
temp %>%
  ggplot(aes(x = GC, y = n, fill = n > 40)) +
    geom_bar(stat = "identity") +
    theme_light() +
  scale_fill_manual(values =c( "#82c0cc", "#EDE7E3"))+
  geom_vline(xintercept = xint, col = "#82c0cc") +
  annotate("text", label = paste0("Median GC is ", xint), 
           x = xint - xint*0.2, y = 5200, 
           size = 4, colour = "#82c0cc", fontface = "bold")

```
The distribution of GC is slightly skewed in the GC-rich side, with a median above 0.5. However, there is an AT-rich fat tail, or even a bimodal distribution. These windows are most probably containing RIP-affected repeated regions.

From there, we need to know if the different collections present GC bias in their sequencing. We expect a batch effect in the sequencing here since we have data coming from a lot of different years and labs (and because batch effect happens in general).
```{r GC bias per collection}
GC_bias = read_tsv(paste0(depth_per_window_dir, "GC_bias_per_sample.txt"))

temp = GC_bias %>%
  filter(Collection != "\\N") %>%
  group_by(Collection) %>%
  dplyr::count() %>%
  filter(n >= 20) 

inner_join(temp, GC_bias) %>%
  group_by(Collection) %>%
  mutate(Median = median(GC_bias_slope)) %>%
 ggplot(., aes(x = reorder(Collection, Median), y = GC_bias_slope, fill = reorder(Collection, Median))) +
  geom_violin(alpha = .7) +
  theme_bw()  +
  theme(axis.text.x = element_text(angle = 30, vjust = 1, hjust = 1),
        plot.margin = unit(c(0.5, 0.5, 0.5, 1), "cm")) +
  labs(x = "Collection", fill = "Collection", y = "GC bias estimate")
```

It is very clear that we do have a batch effect but also that some datasets are very, very biased. The older Hartmann data (also called Qst population) in particular is strongly biased.

<br><br>




# Population structure / biogeography
***
__Question__: Is the world-wide population of _Z.tritici_ structured? If so, is it structured according to geography, host or time (or any other relevant info we hopefully have)?

Previous genomic work has shown very clear structure between populations of _Z.tritici_. However,the sampling was extremely heterogeneous. With a more geographically even sampling, do we also observe a clear-cut structure?
<br>
__Methods__: Analyses to create would be:

 * PCA
 * Structure-like analysis,
 * Tree (rooted on Za to infer origin if pattern?) #TODO
 * Map with cluster if clusters #TODO


## Principal Component Analysis

### PCA with all continents
As a first method to investigate the population structure of _Z.tritici_ at the world-wide scale, I chose to do a principal component analysis based on a subset of the SNPs. This PCA confirms previous results of a geographically structured species. Oceania emerges quite distincly as three separate clusters: one in New-Zealand and two Australian (see below for a more in-depth analysis of this pattern). North-America is also quite serapate. The distinction between the rest of the geographical location is not clear in this PCA, although PC3 might show a slight differenciation between Europe and the Middle-East.



```{r PCA All run and plot, results = F}
snpgdsVCF2GDS(paste0(vcf_dir, vcf_name, ".recode.vcf"),
              paste0(PopStr_dir, vcf_name, ".recode.gds"), method="biallelic.only")
genofile <- snpgdsOpen(paste0(PopStr_dir, vcf_name, ".recode.gds"))
pca <-snpgdsPCA(genofile)
snpgdsClose(genofile)

pca2 = as_tibble(pca$eigenvect) %>% dplyr::select(V1:V6)
colnames(pca2) = c("PC1", "PC2", "PC3", "PC4", "PC5", "PC6")
pca2 = pca2 %>%
  dplyr::mutate(sample_id = pca$sample.id ) %>%
  dplyr::right_join(., Zt_meta, by = c("sample_id" = "ID_file")) %>%
  unite(sample_id, Country, col = "for_display", remove = F) %>%
  filter(!is.na(PC1))

as.tibble(pca$eigenval[!is.na(pca$eigenval)]) %>%
  ggplot(aes(x = c(1:length(pca$eigenval[!is.na(pca$eigenval)])),
             y =value)) + geom_point() +
  theme_bw()


eigen_sum = sum(pca$eigenval[!is.na(pca$eigenval)])
p = ggplot(pca2, aes(x = PC1, y= PC2, text = for_display)) +
  geom_point(aes(color = Continent)) +
  labs(x = paste0("PC 1 (", round(pca$eigenval[1]*100/eigen_sum, 2), "%)"),
       y = paste0("PC 2 (", round(pca$eigenval[2]*100/eigen_sum, 2), "%)")) +
  Color_Continent +
  theme_bw()

#p
ggplotly(p)

q = ggplot(pca2, aes(x = PC3, y= PC4, text = for_display)) +
  geom_point(aes(color = Continent), alpha = .4) +
  labs(x = paste0("PC 3 (", round(pca$eigenval[3]*100/eigen_sum, 2), "%)"),
       y = paste0("PC 4 (", round(pca$eigenval[4]*100/eigen_sum, 2), "%)")) +
  Color_Continent +
  theme_bw()

#q
ggplotly(q)

q = ggplot(pca2, aes(x = PC5, y= PC6, text = for_display)) +
  geom_point(aes(color = Continent), alpha = .4) +
  labs(x = paste0("PC 5 (", round(pca$eigenval[5]*100/eigen_sum, 2), "%)"),
       y = paste0("PC 6 (", round(pca$eigenval[6]*100/eigen_sum, 2), "%)")) +
  Color_Continent +
  theme_bw()

#q
ggplotly(q)
```





``` {r PCA ggpairs}
ggplot2::theme_set(theme_light())
p = ggpairs(pca2, columns = c(1:6),
            ggplot2::aes(col=Continent, fill = Continent, alpha = 0.6),
            title = "PCA based thinned SNPs",
            upper = list(continuous = "points", combo = "box_no_facet"))

for(i in 1:p$nrow) {
  for(j in 1:p$ncol){
    p[i,j] <- p[i,j] + theme_light() + Color_Continent + Fill_Continent
  }
}

p
```


## Structure-like clustering

The clustering here is done by using the snmf method from the LEA R package (http://membres-timc.imag.fr/Olivier.Francois/LEA/) on the same subset of SNPs as the PCA, but without any missing data. I ran the analysis for a K (number of cluster inferred) ranging from 1 to 15 and with 10 repeats for each K.

```{bash format snmf, eval = F}

vcftools --vcf ${VCFDIR}$VCFNAME.recode.vcf \
  --extract-FORMAT-info GT \
  --out ${POPSTR}$VCFNAME

cat  ${POPSTR}$VCFNAME.GT.FORMAT | cut -f 3- \
    > ${POPSTR}$VCFNAME.GT.FORMAT2
cat  ${POPSTR}$VCFNAME.GT.FORMAT | cut -f 1,2 \
    > ${POPSTR}$VCFNAME.GT.FORMAT.pos
head -n1 ${POPSTR}$VCFNAME.GT.FORMAT2 | gsed "s/\t/\n/g"  \
    > ${POPSTR}$VCFNAME.ind
gsed "s/\t//g"  ${POPSTR}$VCFNAME.GT.FORMAT2 | tail -n +2 \
    > ${POPSTR}$VCFNAME.geno
    
datamash transpose < ~/Documents/Postdoc_Bruce/Projects/WW_project/2_Population_structure/Ztritici_global_March2021.genotyped.ALL.filtered.clean.AB_filtered.variants.good_samples.biall_SNP.max-m-1.maf-0.05.thin-1000bp.even_sampling.GT.FORMAT2  |  sed 's/^/>/' | sed 's/\t/\n/' | sed 's/\t//g' | cut -c -150 > ~/Documents/Postdoc_Bruce/Projects/WW_project/2_Population_structure/Ztritici_global_March2021.genotyped.ALL.filtered.clean.AB_filtered.variants.good_samples.biall_SNP.max-m-1.maf-0.05.thin-1000bp.even_sampling.fasta

```

```{r run snmf, eval =F}
project = snmf(paste0(PopStr_dir, vcf_name, ".geno"), K=1:15, entropy = TRUE,
                        repetitions = 10, project = "new", ploidy = 1)
```


```{r reading snmf results}

# Reading the results from the snmf runs
# ______________________________________
#Sample names
indv_snmf = read_tsv(paste0(PopStr_dir, vcf_name, ".ind"), col_names = F)
names(indv_snmf) = "Sample"

#Load project
project = load.snmfProject(paste0(PopStr_dir, vcf_name, ".snmfProject"))

K_list = c(1:15)

#Extracting the clustering info for the best run per K
datalist = list()
for (i in K_list){
  best = which.min(cross.entropy(project, K = i))
  temp = as.data.frame(Q(project, i, best))
  temp= cbind(indv_snmf, temp)

  temp = temp %>%
    gather("Cluster", "Admix_coef", -"Sample") %>%
    mutate(K=i)
   datalist[[i]] = as.tibble(temp)
}

snmf_results_per_K = bind_rows(datalist) %>%
  inner_join(., Zt_meta, by = c("Sample" = "ID_file")) %>%
  unite(Continent, Country, col = "for_display", remove = F)  


#sNMF pretty plots
# _______________
afiles = character(length(K_list))
for (i in K_list){
  best = which.min(cross.entropy(project, K = i))
  afiles[i] = Sys.glob(paste0(PopStr_dir, vcf_name, ".snmf/K",i, "/run", best, "/*Q"))
}

# create a qlist
qlist <- readQBasic(afiles)
al_qlist = alignK(qlist)

lab_set = inner_join(indv_snmf, Zt_meta, by = c("Sample" = "ID_file")) %>%
  dplyr::select(Continent, Country) %>%
  mutate(Continent = ifelse(is.na(Continent), "Unknown", Continent),
         Country = ifelse(is.na(Country), "Unknown", Country))
#Low numbers
from = 2
up_to = 6
p1 <-   plotQ(alignK(qlist[from:up_to], type = "across"),
            imgoutput="join",
            returnplot=T,exportplot=F,
            quiet=T,basesize=11,
            splab= paste0("K=", K_list[from:up_to]),
            grplab=lab_set, ordergrp=T, grplabangle = 40, grplabheight = 2, grplabsize = 2,
            clustercol = K_colors)

grid.arrange(p1$plot[[1]])

#Medium numbers
from = 7
up_to = 11
p2 <-   plotQ(alignK(qlist[from:up_to], type = "across"),
            imgoutput="join",
            returnplot=T,exportplot=F,
            quiet=T,basesize=11,
            splab= paste0("K=", K_list[from:up_to]),
            grplab=lab_set, ordergrp=T, grplabangle = 40, grplabheight = 2, grplabsize = 2,
            clustercol = K_colors)
grid.arrange(p2$plot[[1]])

#High numbers
from = 12
up_to = 15
p3 <-   plotQ(alignK(qlist[from:up_to], type = "across"),
            imgoutput="join",
            returnplot=T,exportplot=F,
            quiet=T,basesize=11,
            splab= paste0("K=", K_list[from:up_to]),
            grplab=lab_set, ordergrp=T, grplabangle = 40, grplabheight = 2, grplabsize = 2,
            clustercol = K_colors)
grid.arrange(p3$plot[[1]])
```

The results from the PCA and from the clutering analysis are coherent: Oceania separates into 3 clusters (one in New_Zealand, and two in Australia) and the North American isolates form two separate clusters. Higher K values also distinguish a Middle-Eastern/African cluster from the European cluster, representing the two extreme points of the gradient found between these populations in the PCA. Despite the high number of isolates from Europe, it's interesting to see that no clustering appears there. 


I need to identify the isolates which belong to each of the clusters. For this, we need to set a threshold, since there are very few (or even no) isolates assigned fully to one only. I test two thresholds: isolates assigned to one cluster with a value higher than 0.75 and 0.9.
```{r snmf threshold}

#Setting thresholds to compare
chosen_threshold = 0.75
chosen_threshold2 = 0.9

pure_by_threshold = bind_rows(snmf_results_per_K %>%
    filter(Admix_coef > chosen_threshold) %>% 
    mutate(Threshold = paste0("> ", chosen_threshold)), 
  snmf_results_per_K %>%
    filter(Admix_coef > chosen_threshold2) %>%
    mutate(Threshold = paste0("> ", chosen_threshold2)))


# Number of pure isolates per K
pure_by_threshold %>%
    dplyr::group_by(K, Threshold) %>%
    dplyr::count() %>%
    ggplot(aes(x = as.factor(K), y = n, fill = Threshold)) +
       geom_bar(stat = "identity", position = "dodge") +
       theme_bw() + scale_fill_manual(values = c("#16697a", "#82c0cc"))+ 
    labs(x = "K", y = "Number of isolates", title = "Pure isolates per K") 


# Number of pure isolates per K per country
temp2 = pure_by_threshold %>%
  dplyr::group_by(Continent, for_display, Cluster, K, Threshold) %>%
  dplyr::count() 

temp2 %>%
  filter(K > 9 & K < 16) %>%
  ggplot(aes(x = Cluster, y = for_display,
             size = n, color = Continent)) +
  geom_point(alpha = 0.3) + Color_Continent+ theme_bw() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  facet_grid(rows = vars(Threshold), cols = vars(K), scales = "free_x") + 
    labs(x = "", y = "", size = "Nb of isolates",
         title = "Pure isolates per country and per K") 
```
Choosing the number K of clusters that best represent the data at hand is always a challenge. First, let's look at the cross-validation results. sNMF estimates an entropy criterion which evaluates the quality of fit of the model to the data, potentially helping to find the best number of ancestral populations. 
```{r choice K snmf}

#Dot plot of the cross-entropy 
#plot(project, col = "goldenrod", pch = 19, cex = 1.2) #native method
cross_ent = list()
for (i in K_list){
  cross_ent[[i]] = as_tibble(cross.entropy(project, K = i), rownames = "NA") %>% 
    mutate( K = i)
  colnames(cross_ent[[i]] ) <- c("Run", "Crossentropy", "K")
}
cross_ent = bind_rows(cross_ent)
temp = cross_ent %>% group_by(K) %>% summarize(average = mean(Crossentropy), minimum = min(Crossentropy))

p1 = ggplot() +
  geom_point(data = cross_ent, aes(x = as.factor(K), y = Crossentropy), alpha = 0.4, size = 2, col = "#82c0cc") +
  geom_point(data = temp, aes(x = as.factor(K), y = minimum), alpha = 0.4, size = 2, col = "#16697a") +
  theme_cowplot() +
    labs(x = "K", y = "Cross-entropy")

p2 = pure_by_threshold %>%
  filter(Threshold == paste0("> ", chosen_threshold)) %>%
  filter(K > 1) %>%
  dplyr::group_by(Cluster, K) %>%
  dplyr::count()%>%
  group_by(K) %>%
  summarize(Size_smallest_cluster = min(n)) %>%
  ggplot(aes(x = as.factor(K), label = Size_smallest_cluster)) +
    geom_bar(aes(y = Size_smallest_cluster, fill = K), stat = "identity") + 
    theme_cowplot() +
    geom_label(aes(y = Size_smallest_cluster + 7)) +
    scale_fill_continuous(high = "#16697a", low = "#82c0cc") +
    labs(x = "K", y = "Size of the smallest cluster")

p3 = pure_by_threshold %>%
  filter(Threshold == paste0("> ", chosen_threshold)) %>%
    dplyr::group_by(K) %>%
    dplyr::count() %>%
    ggplot(aes(x = as.factor(K), y = n, fill = K)) +
       geom_bar(stat = "identity", position = "dodge") +
       theme_bw() +
       scale_fill_continuous(high = "#16697a", low = "#82c0cc") +
    labs(x = "K", y = "Number of assigned samples")

top_row = cowplot::plot_grid(p1, p3 + theme(legend.position = "none"), ncol = 2)
cowplot::plot_grid(top_row, p2 + theme(legend.position = "none"), ncol = 1)
```
In the case of our analysis, we do not have a very clear-cut minimum value for the cross-entropy criterion value. There is however a plateau starting from K=10. I also look at the number of samples assigned to one cluster or another based on the threshold set previously, as well as at the smallest cluster size. Even though, we might get hints that a very real cluster exists in one specific population, if the cluster size is very small, I will not be able to estimate anything with them so there is no point in going to the level of mini-clusters!


```{r sNMF bubbles}
#These values are chosen based on the plot above
chosen_K = 11

#Table
kable(snmf_results_per_K %>%
  filter(K == chosen_K) %>%
  filter(Admix_coef > chosen_threshold) %>%
  dplyr::group_by(Continent, Cluster) %>%
  dplyr::count() %>%
  pivot_wider(names_from = Continent, values_from =n, values_fill = 0))

#Looking at individuals with admixture coef higher than the threshold defined above.
high_anc_coef_snmf = snmf_results_per_K %>%
  filter(K == chosen_K) %>%
  filter(Admix_coef > chosen_threshold)

##Bubble plot
p_cluster = high_anc_coef_snmf %>%
  dplyr::group_by(Continent, for_display, Cluster) %>%
  dplyr::count() %>%
  ggplot(aes(x = for_display, y = Cluster,
             size = n, color = Continent)) +
  geom_point(alpha = 0.5) + Color_Continent+ theme_bw() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
    labs(x = "", 
         title = "Pure isolates per country for the chosen K value",
         subtitle = str_wrap(paste0("Number of genotypes with admix coef > ", chosen_threshold, 
                                    " assigned to ", chosen_K, " clusters."),
                             width = 70),
         size = "Nb of isolates") 
p_cluster

##Writing out tables for later
high_anc_coef_snmf %>% dplyr::select(Sample) %>%
  write_tsv(., file = paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.ind"),
            col_names = F)
high_anc_coef_snmf %>%
  write_tsv(., file = paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.tsv"),
            col_names = T)
```



```{r list samples per cluster}
max_continent = dplyr::count(high_anc_coef_snmf, Cluster, Continent) %>%
  group_by(Cluster) %>%
  mutate(somme = sum(n), prop = n/somme) %>%
  filter(prop > 0.5) %>%
  dplyr::select(Cluster, Continent)

clusters = dplyr::count(high_anc_coef_snmf, Cluster, Continent)

ggplot(high_anc_coef_snmf, aes(x = Cluster, fill = Continent)) +
  geom_bar() +
  theme_cowplot() +
  labs(x = element_blank(), y = "Number of samples") +
  theme(axis.text.x = element_text(angle = 40, hjust = 1, vjust = 1)) +
  Fill_Continent

#Files with all pure isolates per cluster
for (cluster in max_continent %>% pull(Cluster)) {
  file_name = paste0(PopStr_dir, "Sample_list_", cluster, ".args")
  high_anc_coef_snmf %>% filter(Cluster == cluster) %>%
    dplyr::select(Sample) %>%
    write_tsv(file = file_name, col_names = F)
}


#Files with a similar number pure isolates between cluster

minimum_cluster_size = min(dplyr::count(high_anc_coef_snmf, Cluster) %>% dplyr::select(n))

for (cluster in max_continent %>% pull(Cluster)) {
  for (i in 1:10 ){
    file_name = paste0(PopStr_dir, "Sample_list_", cluster, "_", i, ".args")
    temp = high_anc_coef_snmf %>% 
      filter(Cluster == cluster) %>%
      sample_n(size = minimum_cluster_size) %>%
      dplyr::select(Sample)
    write_tsv(temp, file = file_name, col_names = F) 
  }
}

```
For each country, we would like to identify which cluster is the local cluster. Here we define this with "votes": the cluster to which more than half of the non-admixed isolates are originating is considered to be the local cluster. Once, we have identified the local cluster, we can quantify for each country to isolates which are non-admixed (or "pure") isolates from the local cluster, non-admixed from another cluster, or hybrid.

```{r Hybrid category per country}
chosen_coef = snmf_results_per_K %>% 
  filter(K == chosen_K) %>%
  filter(Country != "NA") %>%
  filter(Country != "USA_NA") %>%
  dplyr::select(Sample, Continent, Country, Admix_coef, Cluster, Latitude, Longitude) 

#Identifying the main cluster per country
cluster_per_country = high_anc_coef_snmf %>%
  group_by(Country, Cluster) %>%
  summarise(n = n()) %>%
  mutate(freq = n / sum(n)) %>%
  filter(freq > 0.5) %>%
  dplyr::select(Country, Main_country_cluster = Cluster)


#For each sample, identify if is hybrid, local pure or pure from somewhere else.
status_admix = inner_join(chosen_coef, cluster_per_country) %>% 
  group_by(Sample, Continent, Country) %>%
  mutate(max_admix = max(Admix_coef),
         max_cluster = ifelse(Admix_coef == max_admix, Cluster, "")) %>%
  filter(max_cluster != "") %>%
  mutate(Status = ifelse(max_admix < chosen_threshold, "Hybrid",
                         ifelse(max_cluster == Main_country_cluster, "Pure local", 
                                "Pure other")))

# Summary of hybrid category per country
## As table
kable(status_admix %>% group_by(Country) %>% 
  dplyr::count(Status) %>% 
  pivot_wider(names_from = Status, values_from = n, values_fill = 0))

## As a figure
ggplot(status_admix, aes(x = Country, fill = Status)) +
  geom_bar(position = "fill") + 
  theme_cowplot() +
  theme(axis.title.x = element_blank(), 
        axis.text.x = element_text(angle = 50, hjust = 1, vjust = 1, size = 10)) +
  scale_fill_manual(values =c("#16697a", "#EDE7E3", "#82c0cc")) +
  facet_wrap(vars(Continent), scales = "free")


hybrids = status_admix %>% filter(Status == "Hybrid")
```
The clustering data can also be represented as an average of ancestry coefficient per country. This is done here first with barplots. 
```{r per country ancestry coef}
# Cluster composition per country for all continents
temp = chosen_coef %>%
  group_by(Continent, Country, Cluster) %>%
  summarize(average_coef = mean(Admix_coef)) %>%
  mutate(Cluster2 = ifelse(average_coef < 0.1, "Other", Cluster)) 

#Plot for all continents
temp %>% filter(Continent != "NA") %>%
  filter(Continent != "Asia") %>%
  ggplot(aes(x = Country, y = average_coef, fill = Cluster2))  + 
    geom_bar(stat = "identity") +
    scale_fill_manual(values = c("grey", K_colors) ) +
    facet_wrap(vars(Continent), scales = "free") +
    theme_bw() +
    labs(subtitle = "All continents",
         title = "Cluster ancestry per country",
         xlab = "Average of the ancestry coefficient")

# For North American countries only
temp %>%
  filter(Continent == "North America")  %>%
  ggplot(aes(x = Country, y = average_coef, fill = Cluster2)) + 
    geom_bar(stat = "identity") +
    scale_fill_manual(values = c("grey", K_colors) ) +
    theme_bw()+
  theme(axis.title.x = element_blank(), 
        axis.text.x = element_text(angle = 50, hjust = 1, vjust = 1, size = 10))  +
    labs(subtitle = "North America",
         title = "Cluster ancestry per country",
         xlab = "Average of the ancestry coefficient")

# For European countries only
temp %>%
  filter(Continent == "Europe")  %>%
  ggplot(aes(x = Country, y = average_coef, fill = Cluster2)) + 
    geom_bar(stat = "identity") +
    scale_fill_manual(values = c("grey", K_colors) ) +
    theme_bw()+
  theme(axis.title.x = element_blank(), 
        axis.text.x = element_text(angle = 50, hjust = 1, vjust = 1, size = 10))  +
    labs(subtitle = "Europe",
         title = "Cluster ancestry per country",
         xlab = "Average of the ancestry coefficient")
```
Such visualization is useful but not as intuitive as a map! Let's use the same summarising method but with a more local viewpoint (I use rounded coordinates instead of country).
```{r scatter pies}
#Summarizing based on samples found in neighbouring areas
temp = chosen_coef  %>%
  mutate(Latitude = round(Latitude/2)*2, Longitude = round(Longitude/2)*2)%>%
  group_by(Continent, Country, Cluster, Longitude, Latitude) %>%
  summarize(average_coef = mean(Admix_coef), number_of_isolates = n()) %>%
  filter(!is.na(Latitude))

#Transforming to fit the scatter pie requirements
pies  = temp %>% #filter(number_of_isolates > 2) %>%
  mutate(Cluster2 = ifelse(average_coef < 0.1, "Other", Cluster)) %>%
  group_by(Continent, Longitude, Latitude, Country, Cluster2, number_of_isolates) %>%
  summarize(to_plot = sum(average_coef)) %>%
  pivot_wider(names_from = Cluster2, values_from = to_plot, values_fill = 0) %>%
  mutate(radius = ifelse(number_of_isolates > 10, 1.5, log(number_of_isolates))) %>%
  dplyr::select(-number_of_isolates)  


# Simple map of the world
map1 = ggplot() + 
  theme_void() +
  geom_polygon(data = map_data("world"), aes(x=long, y = lat, group = group), fill="#ede7e3")  +
  scale_size("Number of genomes", limits = c(1, max_circle))  +
  theme(legend.position = "None", 
        panel.border  = element_rect(fill=NA, colour = "grey",size = 0.5, linetype = 1)) +
    scale_fill_manual(values = c("grey", K_colors) )

#Splitting the map into our 3 main focus areas
p1 = map1 + coord_cartesian(xlim=c(-20, 60), ylim=c(20, 70)) + 
  geom_scatterpie(data = pies, mapping = aes(x=Longitude, y=Latitude, group=Country, r = radius), 
                  cols = c("Other", "V10", "V6", "V9", "V3", "V7", "V1", 
                           "V2", "V8", "V11", "V5", "V4"), color=NA, alpha=.8) 
p2 = map1 + coord_cartesian(xlim=c(-160, -40), ylim=c(-80, 80)) + 
  geom_scatterpie(data = pies, mapping = aes(x=Longitude, y=Latitude, group=Country, r = radius*2), 
                  cols = c("Other", "V10", "V6", "V9", "V3", "V7", "V1", 
                           "V2", "V8", "V11", "V5", "V4"), color=NA, alpha=.8)
p3 = map1 + coord_cartesian(xlim=c(115, 175), ylim=c(-65, 10)) + 
  geom_scatterpie(data = pies, mapping = aes(x=Longitude, y=Latitude, group=Country, r = radius*2), 
                  cols = c("Other", "V10", "V6", "V9", "V3", "V7", "V1", 
                           "V2", "V8", "V11", "V5", "V4"), color=NA, alpha=.8)

#Plotting all the maps together! 
aus_map = cowplot::plot_grid(p3, get_legend(isolate_map), ncol = 2, rel_widths = c(1, 0.9))
ligne = cowplot::plot_grid(p1, aus_map, ncol = 1,  rel_heights = c(1, 0.7))
cowplot::plot_grid(p2, ligne, ncol = 2, rel_widths = c(0.7, 1)) 

ggsave(paste0(fig_dir, "Str_scatter_pie.pdf"), width = 18, height = 10, units = "cm")
```


## Population trees
In the steps before, I have learned about population history indirectly by inferring genetic populations from the genomic data. The relationship between the population and the underlying demography is not explicit in these however. It is possible however to infer splits between populations and create a population tree. Here, I use [treemix](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1002967), which takes into account the possibility of gene flow between populations and indeed test of it in the process of creating a population tree.

Because the populations in the clustering were not perfectly distinct from one another, I start with "discretized" populations by choosing only the isolates with high ancestry in one of the sNMF clusters.
```{bash discretized pop vcf, eval = F}
vcftools --vcf ${VCFDIR}$VCFNAME.recode.vcf \
  --keep ${POPSTR}$VCFNAME.high_anc_coef_snmf.ind \
  --remove-filtered-all --extract-FORMAT-info GT \
  --max-missing 1.0 --min-alleles 2 --max-alleles 2 \
  --maf 0.05 \
  --out ${POPSTR}$VCFNAME.high_anc_coef_snmf

cat  ${POPSTR}$VCFNAME.high_anc_coef_snmf.GT.FORMAT | cut -f 3- \
   >  ${POPSTR}$VCFNAME.high_anc_coef_snmf.GT.FORMAT2
```


```{python convert genotype file to treemix}

from collections import defaultdict

#For each isolate, store its pop (as in sampling site) in a dictionary
dict_pop = dict(zip(r.high_anc_coef_snmf["Sample"],
    r.high_anc_coef_snmf["Cluster"]))

#Keep a list of the pop names/coordinates to write in the same order later
all_pops = sorted(list(set(r.high_anc_coef_snmf["Cluster"])))
out_name = r.PopStr_dir + r.vcf_name + ".high_anc_coef_snmf.treemix"


out = open(out_name, "w")
shutup = out.write(" ".join(all_pops) + "\n")

with open(r.PopStr_dir + r.vcf_name + ".high_anc_coef_snmf.GT.FORMAT2", "r") as input_snps :
  for i, snp in enumerate(input_snps) :
    
    #Setting two dictionaries with values at 0
    dict_snp0 = defaultdict(int)
    dict_snp1 = defaultdict(int)
    Lets_write = True
    
    #The first line is the name of the isolates
    if i == 0 :
      indv = snp.strip().split("\t")
      Lets_write = False
    else :
      #Keeping isolate name and allelic value together
      alleles = zip(indv, snp.strip().split("\t"))
            
      #...and counting the O and 1 based on the pop
      for ind, allele in alleles:
        if allele == "0" :
          dict_snp0[dict_pop[ind]] += 1
        elif allele == "1" :
          dict_snp1[dict_pop[ind]] += 1
        else :
          print("Only biallelic please!!!!")
          Lets_write = False
    #If I have not found anything weird, I will write the result to the output file.
    if Lets_write :
      shutup = out.write(" ".join([",".join([str(dict_snp0[pop]), str(dict_snp1[pop])])  for pop in all_pops]) + "\n")


print("All done!")
out.close()
```

```{bash run treemix, eval = F, message = F, results = F}

if [ -f ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix ] ;
then
  gzip ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix
fi

treemix \
  -i ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.gz \
  -o ${POPSTR}$VCFNAME.high_anc_coef_snmf.m0.treemix.out \
  -m 0 -root V7

treemix \
  -i ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.gz \
  -o ${POPSTR}$VCFNAME.high_anc_coef_snmf.m1.treemix.out \
  -m 1 -root V7

treemix \
  -i ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.gz \
  -o ${POPSTR}$VCFNAME.high_anc_coef_snmf.m2.treemix.out \
  -m 2 -root V7

treemix \
  -i ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.gz \
  -o ${POPSTR}$VCFNAME.high_anc_coef_snmf.m3.treemix.out \
  -m 3 -root V7
  
treemix \
  -i ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.gz \
  -o ${POPSTR}$VCFNAME.high_anc_coef_snmf.m4.treemix.out \
  -m 4 -root V7

treemix \
  -i ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.gz \
  -o ${POPSTR}$VCFNAME.high_anc_coef_snmf.m5.treemix.out \
  -m 5 -root V7

treemix \
  -i ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.gz \
  -o ${POPSTR}$VCFNAME.high_anc_coef_snmf.m6.treemix.out \
  -m 6 -root V7
```

```{r plot treemix}
source("/Users/feurtey/Documents/Software/treemix-1.13/src/plotting_funcs.R")
p_cluster
t = plot_tree(paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.m0.treemix.out"))
t = plot_tree(paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.m1.treemix.out"))
t = plot_tree(paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.m2.treemix.out"))
t = plot_tree(paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.m3.treemix.out"))
t = plot_tree(paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.m4.treemix.out"))
t = plot_tree(paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.m5.treemix.out"))
t = plot_tree(paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.m6.treemix.out"))
```

Along with the treemix software, are distribution the software treepop and fourpop. These measure f3 and f4 statistics which test for treeness in population trees.

The three-population test is of the form f3(A;B;C), where a significantly negative value of the f3 statistic implies that population A is admixed. The output is four columns: populations | f3 statistic | standard error | Z-score
```{bash run threepop, eval = F}
threepop -i ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.gz -k 500 | grep "^V" > ${POPSTR}$VCFNAME.high_anc_coef_snmf.treemix.3pop.tab
```

```{r}
kibble(read_delim(paste0(PopStr_dir, vcf_name, ".high_anc_coef_snmf.treemix.3pop.tab"), delim = " ", 
           col_names = c("populations", "f3 statistic", "standard error", "Z-score")) %>%
  filter(`f3 statistic` < 0))
```



#Split tree
```{r subset even sampling}
threshold_per_pop = 6
threshold_per_country = 20

#Subsample
temp = Zt_meta %>%
  #filter(!(ID_file %in% filtered_samples$ID_file)) %>% 
  #unite(Country, Region, col = "Country2", remove = F) %>%
  #mutate(Country_for_filter = ifelse(Country == "USA", Country2, Country)) %>%
  mutate(x = round(Latitude, 1), y = round(Longitude, 1)) %>%
  unite(Coord_for_filter, x, y, sep = ";", remove = F) %>%
  group_by(Coord_for_filter) %>% 
  mutate(Nb_per_coord = n()) %>% 
  group_by(Country) %>% 
  mutate(Nb_per_country= n())
  
small_pop = temp %>%
  filter(Nb_per_coord <= threshold_per_pop) %>%
  filter(Nb_per_country <= threshold_per_country)

temp2 = bind_rows(temp %>%
                    filter(!(ID_file %in% small_pop$ID_file))%>%
                    filter(Nb_per_coord > threshold_per_pop) %>% 
                    group_by(Coord_for_filter) %>%
                    dplyr::sample_n(threshold_per_pop),
                  temp %>%
                    filter(!(ID_file %in% small_pop$ID_file))%>%
                    filter(Nb_per_coord <= threshold_per_pop)) %>% 
        ungroup() %>%
        group_by(Country) %>% 
        dplyr::mutate(Nb_per_country= n())

Zt_meta_even_sampling = bind_rows(temp2 %>% 
                    filter(Nb_per_country > threshold_per_country) %>%
                    dplyr::sample_n(threshold_per_country),
                  temp2 %>% 
                    filter(Nb_per_country <= threshold_per_country)) %>%
  bind_rows(., small_pop) %>%
  ungroup()


write_tsv(Zt_meta_even_sampling %>% dplyr::select(ID_file), 
          paste0(PopStr_dir, "List_samples_even_sampling.txt"),
          col_names = F)


ggplot() +
  geom_bar(data = temp %>% group_by(Continent, Country) %>% dplyr::count(),
           aes(x= Country, y = n, fill = Continent), alpha = 0.4, stat = "identity") +
  geom_bar(data = Zt_meta_even_sampling %>% group_by(Continent, Country) %>% dplyr::count(),
           aes(x= Country, y = n, fill = Continent), alpha = 0.4, stat = "identity") +
  Fill_Continent + theme_bw() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

  
```

```{bash vcftools even sampling}
head ${POPSTR}List_samples_even_sampling.txt

vcftools --vcf ${VCFDIR}$VCFNAME.recode.vcf \
  --keep ${POPSTR}List_samples_even_sampling.txt \
  --remove-filtered-all --extract-FORMAT-info GT \
  --max-missing 1.0 --min-alleles 2 --max-alleles 2 \
  --maf 0.05 \
  --out ${POPSTR}$VCFNAME.even_sampling


cat  ${POPSTR}$VCFNAME.even_sampling.GT.FORMAT | cut -f 3- \
    > ${POPSTR}$VCFNAME.even_sampling.GT.FORMAT2
cat  ${POPSTR}$VCFNAME.even_sampling.GT.FORMAT | cut -f 1,2 \
    > ${POPSTR}$VCFNAME.even_sampling.GT.FORMAT.pos
head -n1 ${POPSTR}$VCFNAME.even_sampling.GT.FORMAT2 | gsed "s/\t/\n/g"  \
    > ${POPSTR}$VCFNAME.even_sampling.ind
gsed "s/\t//g"  ${POPSTR}$VCFNAME.even_sampling.GT.FORMAT2 | tail -n +2 \
    > ${POPSTR}$VCFNAME.even_sampling.geno
    
datamash transpose < ${POPSTR}$VCFNAME.even_sampling.GT.FORMAT2  |  sed 's/^/>/' | sed 's/\t/\n/' | sed 's/\t//g' | cut -c -150 > ${POPSTR}$VCFNAME.even_sampling.fasta
```



<br><br>



# Basic statistics: diversity and differenciation
***

## Summary statistics of diversity per clusters

```{bash}
#rsync -avP  alice@130.125.25.244:/data2/alice/WW_project/3_Sumstats_demography/Sample_list_V*_*_diversity_pi.tsv \
#    /Users/feurtey/Documents/Postdoc_Bruce/Projects/WW_project/3_Sumstats_demography/

echo -e "Subset_samples\tChromosome\tStart\tStop\tPi\tTajimaD\tTheta" > \
  ../3_Sumstats_demography/Diversity_per_cluster.tsv
cat ../3_Sumstats_demography/Sample_list_V*_*_diversity_pi.tsv >>  \
  ../3_Sumstats_demography/Diversity_per_cluster.tsv

```

```{r}
ordering_table = tibble(Cluster = c("V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10", "V11"),
                        Order_tree = c(4, 10, 9, 6, 7, 5, 1, 3, 2, 11, 8))

diversity_values = read_tsv(paste0(Sumstats_dir, "Diversity_per_cluster.tsv"), na = "nan")

temp = diversity_values %>% dplyr::select(-Theta) %>%
  mutate(Subset_samples = str_remove(Subset_samples, "Sample_list_")) %>%
  separate(Subset_samples, into = c("Cluster", "Rep")) %>%
  group_by(Cluster, Chromosome, Start, Stop) %>%
  summarize(Pi = mean(Pi, na.rm = T), TajimaD = mean(TajimaD, na.rm = T)) %>%
  pivot_longer(cols = c(Pi, TajimaD), names_to = "Estimate", values_to = "Value") %>%
  left_join(., ordering_table) %>%
  arrange(Order_tree) 

temp %>% ggplot(aes(x = Cluster, y = Value, fill = Cluster)) +
  geom_violin() +
  geom_boxplot(fill = "white", width = .1) + 
  facet_wrap(vars(Estimate), scales = "free") +
  coord_flip()

```


## Summary statistics of divergence

```{bash, eval = F}
#for i in  {1..11} ; do for j in {1..11} ; do  python Divergence_with_scikit-allel_Fst.py --vcf_file ../1_Variant_calling/4_Joint_calling/Ztritici_global_March2021.genotyped.ALL.filtered.clean.AB_filtered.variants.good_samples.biall_SNP.max-m-1.maf-0.05.thin-1000bp.recode.vcf  --sample_list1 ../2_Population_structure/Sample_list_V${i}.args --sample_list2 ../2_Population_structure/Sample_list_V${j}.args --out_dir ../2_Population_structure/Divergence/ --no_header ; done ; done

# echo -e "Subset1\tSubset2\tHudsons_Fst\tWeir_Cockerham_Fst" > \
 # ../2_Population_structure/Divergence/Divergence.Fst_between_clusters.tsv
# cat ../2_Population_structure/Divergence/Divergence.Fst.Sample_list_V*_vs_Sample_list_V*.tsv >>  \
 # ../2_Population_structure/Divergence/Divergence.Fst_between_clusters.tsv
```

```{r Fst}
ordering_table = tibble(Clusters = c("V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10", "V11"),
                        Order_tree = c(4, 10, 9, 6, 7, 5, 1, 3, 2, 11, 8))

Fst_values = read_tsv(paste0(PopStr_dir, "Divergence.Fst_between_clusters.tsv"))
temp = Fst_values %>% dplyr::select(-Hudsons_Fst) %>%
  mutate(Weir_Cockerham_Fst = ifelse(Weir_Cockerham_Fst < 0, 0, Weir_Cockerham_Fst),
         Subset1 = str_remove(Subset1, "Sample_list_"),
         Subset2 = str_remove(Subset2, "Sample_list_")) %>%
  left_join(., ordering_table, by = c("Subset1" = "Clusters")) %>%
  left_join(., ordering_table, by = c("Subset2" = "Clusters")) %>%
  arrange(Order_tree.x, Order_tree.y) %>%
  dplyr::select(-Order_tree.x, -Order_tree.y) %>%
  pivot_wider(names_from = Subset2, values_from = Weir_Cockerham_Fst)
WC_Fst_values <- as.matrix(temp[,-1])
rownames(WC_Fst_values) <- temp[,1] %>% pull()

corrplot(WC_Fst_values, method="circle", is.corr=FALSE, 
         tl.col = "black", tl.srt=45, tl.cex = 1)
         #type="upper")
```


<br><br>



# Wheat trade and wheat production across the world
```{r wheat prod}

# Get area for country, wheat culture and percentage of land dedicated to wheat
temp = read_csv(paste0(metadata_dir, "FAOSTAT_data_4-15-2021_land_stats.csv"), 
                col_types = "ccdcdcdcddcdc")
wheat_per_country = read_csv(paste0(metadata_dir, "FAOSTAT_data_4-9-2021_crops_production.csv")) %>% 
  filter(Unit == "ha") %>% 
  dplyr::select(Area, `Year Code`, Value)  %>%
  group_by(Area) %>%
  summarize(Wheat_ha = mean(Value)) %>%
  inner_join(.,  filter(temp, Item == "Arable land") %>%
               mutate(Arable_land_area_in_ha = Value * 1000) %>%
               dplyr::select(Area, Arable_land_area_in_ha)) %>%
  mutate(Arable_land_for_wheat = Wheat_ha * 100 / Arable_land_area_in_ha) %>%
  inner_join(., filter(temp, Item == "Land area") %>%
               mutate(Land_area_in_ha = Value * 1000) %>%
               dplyr::select(Area, Land_area_in_ha)) %>%
  mutate(Land_for_wheat = Wheat_ha * 100 / Land_area_in_ha) 

wheat_per_state = read_tsv(paste0(metadata_dir, "USDA_crop_production_2017-2019.txt")) %>%
  mutate(Land_area_in_ha = `Land area` * 1000)  %>% 
  dplyr::select(Area, Year, Wheat_ha, Land_area_in_ha)  %>%
  group_by(Area) %>%
  summarize(Wheat_ha = mean(Wheat_ha), Land_area_in_ha = mean(Land_area_in_ha)) %>%
  mutate(Land_for_wheat = Wheat_ha * 100 / Land_area_in_ha)

wheat_per_country = bind_rows(wheat_per_country, wheat_per_state) 

#Normalize country names
correspondence_table = readxl::read_excel(path = paste0(metadata_dir, "FAO_stats_map_corres.xlsx"), sheet = "Summary")
for (i in c(1:nrow(correspondence_table))) {
  print(pull(correspondence_table[i, 2])) 
  print(pull(correspondence_table[i, 1]))
  wheat_per_country =  wheat_per_country %>% 
    mutate_at(vars(contains('Area')), 
              funs(str_replace(., pull(correspondence_table[i, 2]), pull(correspondence_table[i, 1]))))
}

#Maps 
world2 = left_join(world, wheat_per_country, by = c("region" = "Area"))

temp = Zt_meta %>%
   dplyr::count(Country, Latitude, Longitude, name = "Number_genomes") %>%
   filter(Number_genomes > 0)

ggplot() + theme_void() +
  geom_polygon(data = world2, aes(x=long, y = lat, group = group, fill = Land_for_wheat), alpha=0.7) +
  scale_size("Number of genomes", limits = c(1, max_circle)) +
  scale_fill_gradient(low = "#FEEDD8", high = "goldenrod", na.value="#F7F4F3")


```

```{r diversity per country}
#Setting countries and windows
temp_countries = c("Algeria", "Argentina", "Australia", "Belgium", "Canada", "Chile", "Czech_Republic", 
                   "Denmark", "France", "Germany", "Iran", "Ireland", "Israel", "Netherlands", 
                   "New_Zealand", "Switzerland", "Tunisia", "Turkey", "UK",
                   "USA_Indiana", "USA_Missouri", "USA_Oregon", "USA_Texas", "Uruguay")

windows = read_tsv(paste0(Sumstats_dir, "Windows_for_diversity.bed"), 
                   col_names = c("CHROM", "BIN_START", "BIN_END")) %>%
  mutate(BIN_START = BIN_START +1 )


#Reading diversity data
diversity_list = list()
for (country in temp_countries) {
filename = paste0(nuc_PS_dir,
                  "Ztritici_global_March2021.genotyped.ALL.filtered.clean.AB_filtered.variants.good_samples.max-m-80.",
                   country, ".windowed.pi")

temp = read_tsv(filename) %>% mutate(Country = country)
diversity_list[[country]] = temp
}

temp_diversity = bind_rows(diversity_list) %>%
  inner_join(windows) #%>%
  #mutate(Country = ifelse(str_detect(Country, "^USA"), "USA", Country)) 

#Summarising the genetic diversity for each country
summary_diversity = temp_diversity %>%
  group_by(Country) %>%
  summarize(ave_pi = mean(PI), med_pi = median(PI)) %>%
  left_join(Zt_meta %>% dplyr::select(Country, Continent) %>% distinct()) %>%
  left_join(Zt_meta %>% dplyr::count(Country, name = "Number_of_isolates")) %>%
  mutate(Continent = ifelse(Country == "Australia", "Oceania", Continent)) %>%
  mutate(Continent = ifelse(Country == "New_Zealand", "Oceania", Continent)) %>%
  #mutate(Continent = ifelse(Country == "USA", "North America", Continent)) 
  mutate(Continent = ifelse(str_detect(Country, "^USA"), "North America", Continent)) 

#Adding wheat info to the diversity info
summary_diversity = wheat_per_country %>%
  mutate(Area = ifelse(Area == "United States of America", "USA", Area)) %>%
  mutate(Area = ifelse(Area == "United Kingdom of Great Britain and Northern Ireland", "UK", Area)) %>%
  mutate(Area = ifelse(Area == "Czechia", "Czech_Republic", Area)) %>%
  mutate(Area = ifelse(Area == "New Zealand", "New_Zealand", Area)) %>%
  mutate(Area = ifelse(Area == "Iran (Islamic Republic of)", "Iran", Area)) %>%
  inner_join(., summary_diversity, by = c("Area" = "Country"))

p3 = pivot_longer(summary_diversity, cols = c(Arable_land_for_wheat, Land_for_wheat), 
               names_to = "Wheat_qty_est", values_to = "Percent") %>%
  ggplot(aes(x = med_pi, y = Percent, label = Area, col = Continent)) +
  geom_text() + 
  theme_bw() +
  facet_wrap(vars(Wheat_qty_est), scales = "free_y") +
  Color_Continent + 
  xlim(c(0.004, 0.012))


res.aov2 <- aov(ave_pi ~ Land_for_wheat + Continent, data = summary_diversity)
summary(res.aov2)

p1 = filter(summary_diversity, Continent == "Europe") %>%
  ggplot(aes(x = med_pi, y = Land_for_wheat, label = Area, col = Continent)) +
  geom_text() + 
  theme_bw() +
  Color_Continent

p2 = filter(summary_diversity, Continent != "Europe") %>%
  ggplot(aes(x = med_pi, y = Land_for_wheat, label = Area, col = Continent)) +
  geom_text() + 
  theme_bw() +
  Color_Continent

row = cowplot::plot_grid(p1, p2, nrow = 1) 
cowplot::plot_grid(p3, row, ncol = 1)

#Plot only for Europe
filter(summary_diversity, Continent == "Europe") %>%
  ggplot(aes(x = med_pi, y = Wheat_ha, label = Area, col = Continent)) +
  geom_text() + 
  theme_bw() +
  Color_Continent

res.aov2 <- aov(med_pi ~ Land_for_wheat + Continent + Number_of_isolates, data = summary_diversity)
summary(res.aov2)

# Plot only for North America
filter(summary_diversity, str_detect(Area, "^USA")) %>%
  ggplot(aes(x = med_pi, y = Wheat_ha, label = Area, col = Continent)) +
  geom_text() + 
  theme_bw() +
  Color_Continent

```

```{r}
temp = read_tsv(paste0(Sumstats_dir, "Summary_diversity_pi.tsv"), 
         col_names = c("Subset_size", "Country", "Year", "Lat", "Long", "Repeat", "Mean_pi", "Median_pi")) %>%
  unite(col = "Place", Country, Year, Lat, Long, remove = FALSE) %>%
  #mutate(Country = ifelse(str_detect(Country, "^USA"), "USA", Country)) %>%
  mutate(Country = ifelse(str_detect(Country, "^Australia"), "Australia", Country))%>%
  left_join(Zt_meta %>% dplyr::select(Country, Continent) %>% distinct()) %>%
  mutate(Continent = ifelse(Country == "Australia", "Oceania", Continent)) %>%
  mutate(Continent = ifelse(Country == "NewZealand", "Oceania", Continent)) %>%
  mutate(Continent = ifelse(Country == "USA", "North America", Continent)) 

temp %>%
  ggplot(aes(x = Place, y = Median_pi)) +
  geom_point(col = "goldenrod", alpha = .6) +
  facet_wrap(vars(Subset_size)) +
  coord_flip() + theme_bw()

summary_diversity2 = wheat_per_country %>%
  #mutate(Area = ifelse(Area == "United States of America", "USA", Area)) %>%
  mutate(Area = ifelse(Area == "United Kingdom of Great Britain and Northern Ireland", "UK", Area)) %>%
  mutate(Area = ifelse(Area == "Czechia", "Czech_Republic", Area)) %>%
  mutate(Area = ifelse(Area == "New Zealand", "NewZealand", Area)) %>%
  mutate(Area = ifelse(Area == "Iran (Islamic Republic of)", "Iran", Area)) %>%
  inner_join(., filter(temp, Subset_size == 6) %>% group_by(Country, Continent) %>% summarize(Median_pi = median(Median_pi)), 
             by = c("Area" = "Country")) 

res.aov2 <- aov(Median_pi ~ Wheat_ha + Continent, data = summary_diversity2)
summary(res.aov2)

res.aov2 <- aov(Median_pi ~ Arable_land_for_wheat + Continent, data = summary_diversity2)
summary(res.aov2)

res.aov2 <- aov(Median_pi ~ Land_for_wheat + Continent, data = summary_diversity2)
summary(res.aov2)

res.aov2 <- aov(Median_pi ~ Arable_land_for_wheat, data = summary_diversity2[summary_diversity2$Continent == "Europe", ])
summary(res.aov2)
res.aov2 <- aov(Median_pi ~ Land_for_wheat, data = summary_diversity2[summary_diversity2$Continent == "North America", ])
summary(res.aov2)

pivot_longer(summary_diversity2, cols = c(Arable_land_for_wheat, Land_for_wheat, Wheat_ha), 
               names_to = "Wheat_qty_est", values_to = "Land_use") %>%
  ggplot(aes(x = Median_pi, y = Land_use, label = Area, col = Continent)) +
  geom_text() + 
  theme_bw() +
  facet_wrap(vars(Wheat_qty_est), scales = "free_y") +
  Color_Continent 

filter(summary_diversity2, Continent == "Europe") %>%
  ggplot(aes(x = Median_pi, y = Arable_land_for_wheat, label = Area, col = Continent)) +
  geom_text() + 
  theme_bw()  +
  Color_Continent 
```


```{r}

#Read and correct capitals for coordinates per country
wheat_trade = read_csv(paste0(metadata_dir, "FAOSTAT_data_4-9-2021_detailed_trade_matrix.csv")) 

correspondence_table = readxl::read_excel(path = paste0(metadata_dir, "FAO_stats_map_corres.xlsx"), sheet = "Summary")
for (i in c(1:nrow(correspondence_table))) {
  print(pull(correspondence_table[i, 2])) 
  print(pull(correspondence_table[i, 1]))
  wheat_trade =  wheat_trade %>% 
    mutate_at(vars(contains('Countries')), 
              funs(str_replace(., pull(correspondence_table[i, 2]), pull(correspondence_table[i, 1]))))
}

our_wheat_trade = wheat_trade %>%
  filter(Element == "Import Quantity" & Unit == "tonnes") %>%
  group_by(`Reporter Countries`, `Partner Countries`) %>%
  dplyr::select(`Reporter Countries`, `Partner Countries`, Value) %>%
  summarize(Average_value = mean(Value))


#Read and correct capitals for coordinates per country
capital = read_csv(paste0(metadata_dir, "simple_maps_worldcities.csv")) %>% 
  filter(capital == "primary") %>%
    group_by(country) %>%
    mutate(rank = rank(population, ties.method = "random"))  %>%
    filter(rank == 1)
correspondence_table = readxl::read_excel(path = paste0(metadata_dir, "FAO_stats_map_corres.xlsx"), sheet = "Summary_capital")
for (i in c(1:nrow(correspondence_table))) {
  print(pull(correspondence_table[i, 2])) 
  print(pull(correspondence_table[i, 1]))
  capital =  capital %>% 
    mutate_at(vars(contains('country')), 
              funs(str_replace(., pull(correspondence_table[i, 2]), pull(correspondence_table[i, 1]))))
}

temp = inner_join(our_wheat_trade, capital %>%
                   dplyr::select(country, yend = lat, xend = lng),
                   by = c("Reporter Countries" = "country")) %>%
        inner_join(., capital %>%
                   dplyr::select(country, y = lat, x = lng),
                   by = c("Partner Countries" = "country")) 

temp2 = filter(temp,`Partner Countries` != `Reporter Countries`) %>% 
  filter(Average_value > 10000) %>% distinct()


#
ggplot() + theme_void() +
  geom_polygon(data = world2, 
               aes(x=long, y = lat, group = group, fill = Land_for_wheat), 
               alpha=0.7) +
  scale_fill_gradient(low = "#FEEDD8", high = "#faa307", na.value="#F7F4F3") +
  geom_curve(data = temp2, aes(x = x, y = y, xend = xend, yend = yend, 
                               size = Average_value, alpha = Average_value), 
             curvature = 0.2, color = "#432818") +
  scale_size_continuous(guide = FALSE, range = c(0.02, 0.5)) 



```


